{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sheet 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Principal Component Analysis\n",
    "### (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement PCA (fill in the blanks in the function below)\n",
    "\n",
    "def pca(data, n_components=None):\n",
    "    \"\"\"\n",
    "    Principal Component Analysis on a p x N data matrix.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : np.ndarray\n",
    "        Data matrix of shape (p, N).\n",
    "    n_components : int, optional\n",
    "        Number of requested components. By default returns all components.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray, np.ndarray\n",
    "        the pca components (shape (n_components, p)) and the projection (shape (n_components, N))\n",
    "\n",
    "    \"\"\"\n",
    "    # set n_components to p by default\n",
    "    n_components = data.shape[0] if n_components is None else n_components\n",
    "    assert n_components <= data.shape[0], f\"Got n_components larger than dimensionality of data!\"\n",
    "    \n",
    "    # center the data\n",
    "    \n",
    "    # compute X times X transpose\n",
    "    \n",
    "    # compute the eigenvectors and eigenvalues\n",
    "    \n",
    "    # sort the eigenvectors by eigenvalue and take the n_components largest ones\n",
    "    \n",
    "    # compute X_projected, the projection of the data to the components\n",
    "    \n",
    "    return components, X_projected  # return the n_components first components and the pca projection of the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example data to test your implementation \n",
    "# All the asserts on the bottom should go through if your implementation is correct\n",
    "\n",
    "data = np.array([\n",
    "    [ 1,  0,  0, -1,  0,  0],\n",
    "    [ 0,  3,  0,  0, -3,  0],\n",
    "    [ 0,  0,  5,  0,  0, -5]\n",
    "], dtype=np.float32)\n",
    "\n",
    "# add a random offset to all samples. it should not affect the results\n",
    "data += np.random.randn(data.shape[0], 1)\n",
    "\n",
    "n_components = 2\n",
    "components, projection = pca(data, n_components=n_components)  # apply your implementation\n",
    "\n",
    "# the correct results are known (up to some signs)\n",
    "true_components = np.array([[0, 0, 1], [0, 1, 0]], dtype=np.float32)\n",
    "true_projection = np.array([\n",
    "    [ 0,  0,  5,  0,  0, -5],\n",
    "    [ 0,  3,  0,  0, -3,  0]\n",
    "], dtype=np.float32)\n",
    "\n",
    "# check that components match, up to sign\n",
    "assert isinstance(components, np.ndarray), f'Expected components to be numpy array but got {type(components)}'\n",
    "assert components.shape == true_components.shape, f'{components.shape}!={true_components.shape}'\n",
    "assert np.allclose(np.abs(components * true_components).sum(1), np.ones(n_components)), f'Components not matching'\n",
    "\n",
    "# check that projections agree, taking into account potentially flipped components\n",
    "assert isinstance(projection, np.ndarray), f'Expected projection to be numpy array but got {type(projection)}'\n",
    "assert projection.shape == (n_components, data.shape[1]), f'Incorrect shape of projection: Expected {(n_components, data.shape[1])}, got {projection.shape}'\n",
    "assert np.allclose(projection, true_projection * (components * true_components).sum(1, keepdims=True), atol=1e-6), f'Projections not matching'\n",
    "\n",
    "print('Test successful!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data (it is a subset of the data at https://opendata.cern.ch/record/4910#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.load('data/dijet_features.npy')\n",
    "labels = np.load('data/dijet_labels.npy')\n",
    "label_names = ['b', 'c', 'q']  # bottom, charm or light quarks\n",
    "\n",
    "print(f'{features.shape=}, {labels.shape=}')  # print the shapes\n",
    "\n",
    "# TODO: print how many samples of each class are present in the data (hint: numpy.unique)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: subtract the mean of each feature to center the data\n",
    "\n",
    "# TODO: divide by the standard deviation of each feature to normalize the variance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c)\n",
    "Compute a 2D PCA projection and make a scatterplot of the result, once without color, once coloring the dots by label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: apply PCA as implemented in (a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: make a scatterplot of the PCA projection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: make a scatterplot, coloring the dots by their label and including a legend with the label names\n",
    "# (hint: one way is to call plt.scatter once for each of the three possible labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Nonlinear Dimension Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap  # import umap-learn, see https://umap-learn.readthedocs.io/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you have not done 1(b) yet, you can load the normalized features directly:\n",
    "features = np.load('data/dijet_features_normalized.npy')\n",
    "labels = np.load('data/dijet_labels.npy')\n",
    "label_names = ['b', 'c', 'q']  # bottom, charm or light quarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Apply umap on the normalized jet features from excercise 1. It will take a couple of seconds.\n",
    "# note: umap uses a different convention regarding the feature- and sample dimension, N x p instead of p x N!\n",
    "\n",
    "reducer = umap.UMAP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: make a scatterplot of the UMAP projection\n",
    "\n",
    "# TODO: make a scatterplot, coloring the dots by their label and including a legend with the label names\n",
    "# (hint: one way is to call plt.scatter once for each of the three possible labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for n_neighbors in (2, 4, 8, 15, 30, 60, 100):\n",
    "    # TODO: repeat the above, varying the n_neighbors parameter of UMAP\n",
    "    reducer = umap.UMAP(n_neighbors=n_neighbors)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for n_components in (2, 4, 8, 16, 32, 64, len(features)):\n",
    "    # TODO: project to the n-components first principal components \n",
    "    #       (use your implementation from ex. 1 or PCA from scikit-learn)\n",
    "    \n",
    "    # TODO: apply UMAP to get from n_components to just two dimensions\n",
    "    \n",
    "    # TODO: again, make scatterplots as before"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mlphys]",
   "language": "python",
   "name": "conda-env-mlphys-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
